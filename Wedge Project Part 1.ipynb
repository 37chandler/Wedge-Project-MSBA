{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35604d12",
   "metadata": {},
   "source": [
    "## Wedge Project - Sam Beighle MSBA Fall 23\n",
    "Part 1 - Connecting to Google Big Query Using Clean Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e0791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install google-cloud-bigquery google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bff1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas-gbq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e9f140",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb64bcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "\n",
    "import re\n",
    "import datetime\n",
    "import io\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_gbq\n",
    "\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daa41dc",
   "metadata": {},
   "source": [
    "### Connect to GBQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c4a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_path = r\"C:\\Users\\Sam Beighle\\Documents\\ADA\"\n",
    "service_file = r'C:\\Users\\Sam Beighle\\Documents\\ADA\\wedge-project-sam-beighle-100816fecfc7.json' \n",
    "gbq_proj_id = 'wedge-project-sam-beighle' \n",
    "\n",
    "private_key = os.path.join(service_path, service_file)\n",
    "credentials = service_account.Credentials.from_service_account_file(private_key)\n",
    "\n",
    "client = bigquery.Client(credentials = credentials, project=gbq_proj_id)\n",
    "for item in client.list_datasets() : \n",
    "    print(item.full_dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa71ead",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c79b9067",
   "metadata": {},
   "source": [
    "### GBQ and extract Zips, and upload to GBQ as tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4380dfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Set your Google Cloud project ID\n",
    "gbq_proj_id = 'wedge-project-sam-beighle'\n",
    "\n",
    "# Set the path to your service account key JSON file and authenticate\n",
    "service_path = r\"C:\\Users\\Sam Beighle\\Documents\\ADA\"\n",
    "service_file = r'C:\\Users\\Sam Beighle\\Documents\\ADA\\wedge-project-sam-beighle-100816fecfc7.json'\n",
    "\n",
    "private_key = os.path.join(service_path, service_file)\n",
    "credentials = service_account.Credentials.from_service_account_file(private_key)\n",
    "\n",
    "# Create a BigQuery client\n",
    "client = bigquery.Client(credentials=credentials, project=gbq_proj_id)\n",
    "\n",
    "# Path to the zip file containing CSVs\n",
    "zip_file_path = r'C:\\Users\\Sam Beighle\\Documents\\ADA\\wedge-clean-files.zip'\n",
    "\n",
    "# Extract the CSVs from the zip file and upload them as tables\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_file:\n",
    "    for csv_file_name in zip_file.namelist():\n",
    "        if csv_file_name.endswith('.csv'):\n",
    "            # Extract the table name from the CSV file name (excluding the .csv extension)\n",
    "            table_name = os.path.splitext(os.path.basename(csv_file_name))[0]\n",
    "            \n",
    "            # Specify the dataset and table ID\n",
    "            dataset_id = 'test'  # Replace with your dataset ID\n",
    "            table_id = table_name  # Use the CSV file name as the table ID\n",
    "            \n",
    "            # Create a BigQuery table schema (assuming you have a header row in your CSV)\n",
    "            schema = []\n",
    "            \n",
    "            # Upload the CSV data as a table\n",
    "            job_config = bigquery.LoadJobConfig(\n",
    "                schema=schema,\n",
    "                source_format=bigquery.SourceFormat.CSV,\n",
    "            )\n",
    "            \n",
    "            with zip_file.open(csv_file_name) as csv_file:\n",
    "                # Create a BytesIO object to read the binary data\n",
    "                csv_data_stream = BytesIO(csv_file.read())\n",
    "                \n",
    "                # Upload the data as a table\n",
    "                load_job = client.load_table_from_file(\n",
    "                    csv_data_stream,\n",
    "                    dataset_id,\n",
    "                    table_id,\n",
    "                    job_config=job_config,\n",
    "                ).result()\n",
    "            \n",
    "            print(f\"Uploaded CSV '{csv_file_name}' as table '{table_id}' in dataset '{dataset_id}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885e619a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a57db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041aa97b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
